"""
Non-Maximum Suppression (NMS) for Raw Image Detections

This script applies NMS to filter overlapping detections from the prediction results.
It processes JSON files generated by the detection phase, handling window-based detections.

Features:
- Calculates global coordinates for detections from different windows
- Applies NMS with IoU threshold
- Preserves detection metadata
- Handles batch processing of multiple images

Input:
    - JSON files containing window-based detections
Output:
    - Filtered JSON files with non-overlapping detections
"""

import json
from typing import List, Dict
import numpy as np
import os
from pathlib import Path
from tqdm import tqdm

def calculate_iou(box1: List[float], box2: List[float]) -> float:
    """
    Calculate Intersection over Union (IoU) between two bounding boxes.

    Args:
        box1: First bounding box in format [x1, y1, x2, y2]
        box2: Second bounding box in format [x1, y1, x2, y2]
    
    Returns:
        float: IoU value between 0 and 1
    """
    # Calculate intersection coordinates
    x1 = max(box1[0], box2[0])
    y1 = max(box1[1], box2[1])
    x2 = min(box1[2], box2[2])
    y2 = min(box1[3], box2[3])
    
    # Calculate intersection area
    if x2 < x1 or y2 < y1:
        return 0.0
    intersection = (x2 - x1) * (y2 - y1)
    
    # Calculate box areas
    area1 = (box1[2] - box1[0]) * (box1[3] - box1[1])
    area2 = (box2[2] - box2[0]) * (box2[3] - box2[1])
    
    # Calculate IoU
    iou = intersection / (area1 + area2 - intersection)
    return iou

def nms_for_windows(data: Dict) -> Dict:
    """
    Apply NMS to detections across all windows.
    
    Args:
        data: Dictionary containing detection results
    
    Returns:
        Dict: Processed detection results with overlapping boxes removed
    """
    # Deep copy original data
    processed_data = data.copy()
    windows = processed_data["windows"]
    
    # Collect all detections with global coordinates
    all_detections = []
    for window_key, detections in windows.items():
        for detection in detections:
            # Add window coordinates to bbox coordinates for global position
            x_offset, y_offset = detection["window_coords"]
            bbox = detection["bbox"]
            global_bbox = [
                bbox[0] + x_offset,
                bbox[1] + y_offset,
                bbox[2] + x_offset,
                bbox[3] + y_offset
            ]
            
            all_detections.append({
                "window_key": window_key,
                "detection": detection,
                "global_bbox": global_bbox,
                "confidence": detection["confidence"]
            })
    
    # Sort by confidence score in descending order
    all_detections.sort(key=lambda x: x["confidence"], reverse=True)
    
    # Track boxes to remove
    to_remove = set()
    
    # Perform NMS
    for i, det_i in enumerate(all_detections):
        if i in to_remove:
            continue
            
        for j in range(i + 1, len(all_detections)):
            if j in to_remove:
                continue
                
            iou = calculate_iou(det_i["global_bbox"], all_detections[j]["global_bbox"])
            if iou >= 0.5:  # IoU threshold
                to_remove.add(j)
    
    # Remove overlapping detections from original data
    for window_key in windows:
        if not windows[window_key]:  # Skip empty lists
            continue
            
        windows[window_key] = [
            det["detection"] 
            for i, det in enumerate(all_detections)
            if det["window_key"] == window_key and i not in to_remove
        ]
    
    return processed_data

def process_file(input_path: str, output_path: str):
    """
    Process a single JSON file and save filtered results.
    
    Args:
        input_path: Path to input JSON file
        output_path: Path to save output JSON file
    """
    try:
        # Read input file
        with open(input_path, 'r') as f:
            data = json.load(f)
        
        # Apply NMS
        processed_data = nms_for_windows(data)
        
        # Save processed results
        with open(output_path, 'w') as f:
            json.dump(processed_data, f, indent=4)
            
    except Exception as e:
        print(f"Error processing file {input_path}: {str(e)}")
        raise

def process_folder(input_folder: str, output_folder: str):
    """
    Process all JSON files in the input folder.
    
    Args:
        input_folder: Path to folder containing input JSON files
        output_folder: Path to save processed JSON files
    """
    # Create output folder if it doesn't exist
    Path(output_folder).mkdir(parents=True, exist_ok=True)
    
    # Get all JSON files
    json_files = [f for f in os.listdir(input_folder) if f.endswith('.json')]
    
    if not json_files:
        print(f"No JSON files found in {input_folder}")
        return
    
    print(f"Found {len(json_files)} JSON files to process")
    
    # Process files with progress bar
    for json_file in tqdm(json_files, desc="Processing files"):
        input_path = os.path.join(input_folder, json_file)
        output_path = os.path.join(output_folder, json_file)
        
        try:
            process_file(input_path, output_path)
        except Exception as e:
            print(f"Failed to process {json_file}: {str(e)}")
            continue

def main():
    """Main execution function"""
    try:
        # Define input/output paths
        input_folder = "/path/to/input/results"
        output_folder = "/path/to/output/nms_results"
        
        # Process all files
        process_folder(input_folder, output_folder)
        
        print("Processing completed successfully")
        return 0
        
    except Exception as e:
        print(f"Error in main execution: {str(e)}")
        return 1

if __name__ == "__main__":
    exit(main())